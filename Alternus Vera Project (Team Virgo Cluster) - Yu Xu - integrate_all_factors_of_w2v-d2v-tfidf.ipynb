{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m_x2mbHBQpRe"
   },
   "source": [
    "# Alternus Vera Project (Team Virgo Cluster) - Yu Xu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gjy0OwF6r8ib"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Due December 12, 2018\n",
    "By Team Virgo Cluster\n",
    "\n",
    "### About this Notebook\n",
    "\n",
    "This python notebook downloads csv files from different sources uploaded by\n",
    "the individual members of the team working on each factor(s).\n",
    "\n",
    "After downloading the csv files, the factor columns are extracted. Using\n",
    "weighted values and factor score/ranks, we generate a score to determine \"fake\"-ness of\n",
    "each news article. Polynomial equation is provided in this notebook.\n",
    "\n",
    "Since this notebook is the last stage of the pipeline, and generates the final\n",
    "aggregated score for fake news classification, **this notebook can be\n",
    "considered the official notebook of our Alternus Vera project**.\n",
    "\n",
    "However, please refer to the **individual notebooks** and **combined (team) notebook**\n",
    "to see how the individual csv files are generated one per factor. The derivations are done\n",
    "in smaller notebooks, and only aggregations and generating polynomial\n",
    "are done here. All relevant references are made in individual notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Le_zBnvO9Il"
   },
   "source": [
    "### About Team Virgo Cluster\n",
    "\n",
    "###  Contributions\n",
    "\n",
    "Sy Le (006088940) : data import and wrangling, tokenization, remove stopwords, remove stemmings, feature selection using Context of the statement and Social reliability\n",
    "\n",
    "Mojdeh Keykhanzadeh(008129589) : remove punctuation , apply ngrams,researched about IBM Faireness , Sentiment Analysis of text , Frequency of word visualization ,Topic modeling using Gensim , finding cosine similarity score of title and text\n",
    "\n",
    "Hyunwook Shin (012507417) : Coverage Score and Political Bias/Spectrum Analysis, Data enrichment: all news dataset (50K+ articles), political messages dataset (LDA, TF-IDF, MultinomialNB, random forrest, word2vec, doc2vec), identifying factors, and assigning weightage to individual factors.\n",
    "\n",
    "Lin Cheng (012484459) : Interpret and transform data, use TF-IDF Vectorizer with customized tokenizer + SVD to produce a matrix, apply different classifiers and hyperparameter tuning and build a model with 95.6% accuracy\n",
    "\n",
    "Yu Xu (012502048): Explored ways to gather topics from the dataset. Explored tf-idf ranking. Explored pipeline + GridSearch for the best n_component of LDA for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vH8lGutKNBYT"
   },
   "source": [
    "# Notebooks\n",
    "\n",
    "### Team Notebook\n",
    "\n",
    "**Combined notebook** can be found here, but to cut down run time and save resources, we used individual notebooks to run distillation and scoring for each factor. So please do not run the combined notebook, but simply refer to it as the code source.\n",
    "\n",
    "https://colab.research.google.com/drive/1bOoY6V0ytxSigKuZ6lJntNWJJcTM_6wU#scrollTo=myrJOvEVIhue\n",
    "\n",
    "### Individual Notebooks\n",
    "\n",
    "**Hyunwook Notebook**\n",
    "https://colab.research.google.com/drive/1gOvKRrE7g7ldiNIpoYbkx3hnOW9LT66T#scrollTo=BXdP1JmmfaSp\n",
    "\n",
    "**Mojdeh Notebook**\n",
    "https://colab.research.google.com/drive/1Xz_-XGbzTdK53INTXI-WqOcDW5gWbl3o#scrollTo=XUZqgzzOIQ_M&uniqifier=2\n",
    "\n",
    "**Sy Notebook**\n",
    "https://colab.research.google.com/drive/1QfCxEI_agvoMclqVujmJskXTspUSeDAH\n",
    "\n",
    "**Lin Notebook**\n",
    "https://colab.research.google.com/drive/1dVuCq4kcgIhl9vK1CzR8EFoWqi0VzHT9\n",
    "\n",
    "**Gene Notebook**\n",
    "https://colab.research.google.com/drive/17Veeq4ovc7ToWbhTMGEcfPJ6TmOzoEHJ\n",
    "\n",
    "(Data processing template by Gene for Aggregation)\n",
    "https://colab.research.google.com/drive/1rLCLUZlNylQ0t7d_-lYaAi5GKisHn290#scrollTo=Ep7WNDIqg4pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Alarming</font>: this notebook may take >30 mins to run. But I've run through it and guarantee it runs successfully!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oHk0PCfrrRRc"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "cXXQkvXzrF5m",
    "outputId": "1269ee33-9313-4fc0-f2ae-40ff108b6d33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/yuxu/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/yuxu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/yuxu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/yuxu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import io\n",
    "import requests\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_selection import chi2\n",
    "from string import punctuation\n",
    "from nltk import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iErqgBa7rjv3"
   },
   "source": [
    "## Downloading Individual CSV Files (Factors)\n",
    "\n",
    "The individual CSV files should have the same rows (fake news and all news dataset concatenated together), with articles in the same order as\n",
    "prepared originally by Gene.\n",
    "\n",
    "1. Fake news comes first before Non-fake (all) news\n",
    "2. Ensuring that the counts are as follows:\n",
    "\n",
    "```\n",
    "<your_labeled_csv_data>.type.value_counts()\n",
    "0    51507\n",
    "1    11492\n",
    "Name: type, dtype: int64\n",
    " ```\n",
    " \n",
    " 3. Ensuring that the labels are complete with no \"holes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P0sNcQflttmG"
   },
   "outputs": [],
   "source": [
    "def get_parsed_data(url):\n",
    "    return pd.read_csv(io.StringIO(requests.get(url, verify=False).content.decode('utf-8')), sep=',', header='infer')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFmt5gTP98Uu"
   },
   "source": [
    "### Master Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "a_TzjkGz99o3",
    "outputId": "ee358ac6-4b69-48a8-fd88-256780225ae7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_venv/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/anaconda3/envs/nlp_venv/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/anaconda3/envs/nlp_venv/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "data_kg_fake_news = get_parsed_data('https://github.com/synle/machine-learning-sample-dataset/raw/master/liar_dataset/kaggle/kaggle-fake.csv')\n",
    "data_kg_nonfake_news = get_parsed_data('https://dock2.hyunwookshin.com/public/cmpe257_a1/articles1.csv')\n",
    "data_kg_nonfake_news.rename(columns={\"content\": \"text\"}, inplace=True)\n",
    "data_kg_nonfake_news['type'] = 0\n",
    "data_kg_fake_news.loc[data_kg_fake_news['type']!='bs', 'type'] = 0\n",
    "data_kg_fake_news.loc[data_kg_fake_news['type']=='bs', 'type'] = 1\n",
    "\n",
    "\n",
    "all_data = pd.concat([data_kg_fake_news[['title','text','type']], data_kg_nonfake_news[['title','text','type']]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNvvJJVV-SH8"
   },
   "source": [
    "Verify dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLhLZ9Re-Tyn"
   },
   "outputs": [],
   "source": [
    "assert all_data.shape[0] == 62999, \"Please review your csv\" # INSERTED BY JAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pkg1BJ0vrmr6"
   },
   "source": [
    "### Gene "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "BoKMVKc1rQSe",
    "outputId": "7060ab8d-8841-4e93-be7a-9becbf3d3530"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_venv/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "w2v_d2v_factors = pd.read_csv(io.StringIO(requests.get('https://dock2.hyunwookshin.com/public/cmpe257_a1/fake_news_w2v_d2v_only.csv', \\\n",
    "                                                       verify=False).content.decode('utf-8')), sep=',', header=None, names=['text_w2v_mean','title_w2v_mean','text_d2v_mean','title_d2v_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Qr9Vnu4ACvvJ",
    "outputId": "1293aa42-4299-4e05-c4bf-198cdd97bb4b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_w2v_mean</th>\n",
       "      <th>title_w2v_mean</th>\n",
       "      <th>text_d2v_mean</th>\n",
       "      <th>title_d2v_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.052476</td>\n",
       "      <td>0.066654</td>\n",
       "      <td>-0.220385</td>\n",
       "      <td>-0.114133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.126095</td>\n",
       "      <td>-0.309628</td>\n",
       "      <td>-0.048451</td>\n",
       "      <td>0.017952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.095904</td>\n",
       "      <td>-0.209579</td>\n",
       "      <td>-0.118836</td>\n",
       "      <td>-0.079925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.027249</td>\n",
       "      <td>-0.071950</td>\n",
       "      <td>-0.038647</td>\n",
       "      <td>-0.168344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.075030</td>\n",
       "      <td>-0.066515</td>\n",
       "      <td>-0.155317</td>\n",
       "      <td>-0.074950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_w2v_mean  title_w2v_mean  text_d2v_mean  title_d2v_mean\n",
       "0      -0.052476        0.066654      -0.220385       -0.114133\n",
       "1      -0.126095       -0.309628      -0.048451        0.017952\n",
       "2      -0.095904       -0.209579      -0.118836       -0.079925\n",
       "3      -0.027249       -0.071950      -0.038647       -0.168344\n",
       "4      -0.075030       -0.066515      -0.155317       -0.074950"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_d2v_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Elo9-tKuCd7S"
   },
   "outputs": [],
   "source": [
    "assert w2v_d2v_factors.shape[0] == 62999, \"Please review your csv\" # INSERTED BY JAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KmJ7uhRArn31"
   },
   "source": [
    "### Mojdeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "Tiji-Uq_rrvE",
    "outputId": "2d6ef330-e47b-4015-90d1-8a9f460050a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_venv/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "sentiment_factors = get_parsed_data('https://raw.githubusercontent.com/mojdehkeykhanzadeh/NLP_Proj/master/all_news_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1982
    },
    "colab_type": "code",
    "id": "8sM7Ik6tJq0y",
    "outputId": "7f073ae4-11eb-4f12-ce0d-1e40e5cb829c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title_senti_neg</th>\n",
       "      <th>title_senti_neu</th>\n",
       "      <th>title_senti_pos</th>\n",
       "      <th>title_senti_cmpd</th>\n",
       "      <th>text_senti_neg</th>\n",
       "      <th>text_senti_neu</th>\n",
       "      <th>text_senti_pos</th>\n",
       "      <th>text_senti_cmp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.7783</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8316</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9517</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  title_senti_neg  title_senti_neu  title_senti_pos  \\\n",
       "0           0           0.4588             0.00            0.625   \n",
       "1           1           0.0000             0.00            1.000   \n",
       "2           2           0.0000             0.00            1.000   \n",
       "3           3          -0.7783             0.43            0.570   \n",
       "4           4           0.0000             0.00            1.000   \n",
       "\n",
       "   title_senti_cmpd  text_senti_neg  text_senti_neu  text_senti_pos  \\\n",
       "0             0.375         -0.3400           0.209           0.606   \n",
       "1             0.000         -0.2960           0.063           0.887   \n",
       "2             0.000          0.8957           0.021           0.871   \n",
       "3             0.000          0.8316           0.133           0.517   \n",
       "4             0.000          0.9517           0.066           0.765   \n",
       "\n",
       "   text_senti_cmp  \n",
       "0           0.185  \n",
       "1           0.050  \n",
       "2           0.108  \n",
       "3           0.350  \n",
       "4           0.170  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pc64WKe98sMt"
   },
   "outputs": [],
   "source": [
    "assert sentiment_factors.shape[0] == 62999, \"Please review your csv\" # INSERTED BY JAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GBBX3ClJrpP_"
   },
   "source": [
    "### Hyunwook (James)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgZ1J_7WtJEi"
   },
   "source": [
    "News event coverage scores ranging from 0 to 18 are added to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "8N8r9LMprrLy",
    "outputId": "9a5acefe-50dd-4111-aaf9-40a31a6c1e0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_venv/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "coverage_factor = get_parsed_data('https://dock2.hyunwookshin.com/public/cmpe257_a1/all_data_coverage_condensed.processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "b5xA0mzMwU6s",
    "outputId": "4e7f6a00-16a8-4dc9-909f-beca30d73ee3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Hillary Goes Absolutely Berserk On Protester A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>BREAKING! NYPD Ready To Make Arrests In Weiner...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>WOW! WHISTLEBLOWER TELLS CHILLING STORY Of Mas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>BREAKING: CLINTON CLEARED...Was This A Coordin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>EVIL HILLARY SUPPORTERS Yell \"F*ck Trump\"…Burn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  Coverage\n",
       "0           0  Muslims BUSTED: They Stole Millions In Gov’t B...         0\n",
       "1           1  Re: Why Did Attorney General Loretta Lynch Ple...         0\n",
       "2           2  BREAKING: Weiner Cooperating With FBI On Hilla...         0\n",
       "3           3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...         0\n",
       "4           4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...         0\n",
       "5           5  Hillary Goes Absolutely Berserk On Protester A...         0\n",
       "6           6  BREAKING! NYPD Ready To Make Arrests In Weiner...         0\n",
       "7           7  WOW! WHISTLEBLOWER TELLS CHILLING STORY Of Mas...         0\n",
       "8           8  BREAKING: CLINTON CLEARED...Was This A Coordin...         0\n",
       "9           9  EVIL HILLARY SUPPORTERS Yell \"F*ck Trump\"…Burn...         0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage_factor.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fhojyGgZ9PoN"
   },
   "outputs": [],
   "source": [
    "assert coverage_factor.shape[0] == 62999, \"Please review your csv\" # INSERTED BY JAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YB6iIc4TrsiU"
   },
   "source": [
    "### Sy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x3_d45Insa7t"
   },
   "source": [
    "Here we have 3 scores for reputation and social activeness, and all of them ranges from 0 to 10\n",
    "\n",
    "*   calculated_reputation_score\n",
    "*   calculated_spam_score\n",
    "*   calculated_social_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "V7kWJVbtrt_X",
    "outputId": "62f85498-dcb9-4ec8-bf33-d6b57c4537b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_venv/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/anaconda3/envs/nlp_venv/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "social_reliability_factors = get_parsed_data('https://github.com/synle/machine-learning-sample-dataset/raw/master/liar_dataset/factor_social_reliablity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1945
    },
    "colab_type": "code",
    "id": "YTLDLgg6r9X9",
    "outputId": "4cde0452-1470-4789-eb74-ce9a4226ee2c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>calculated_reputation_score</th>\n",
       "      <th>calculated_spam_score</th>\n",
       "      <th>calculated_social_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type  calculated_reputation_score  calculated_spam_score  \\\n",
       "0           0     0                            8                   0.00   \n",
       "1           1     0                            8                   0.00   \n",
       "2           2     0                            8                   0.00   \n",
       "3           3     0                            8                   0.68   \n",
       "4           4     0                            8                   8.65   \n",
       "\n",
       "   calculated_social_score  \n",
       "0                    0.011  \n",
       "1                    0.011  \n",
       "2                    0.011  \n",
       "3                    0.000  \n",
       "4                    0.000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social_reliability_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHmSgvNC9U1H"
   },
   "outputs": [],
   "source": [
    "assert social_reliability_factors.shape[0] == 62999, \"Please review your csv\" # INSERTED BY JAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XxeYDeRwrutT"
   },
   "source": [
    "### Lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "4-Nv-IOyrwJO",
    "outputId": "756a45eb-f473-4def-e276-bf23b3372444"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_venv/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/anaconda3/envs/nlp_venv/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "\n",
    "def get_parsed_data2(url):\n",
    "    return pd.read_csv(io.StringIO(requests.get(url, verify=False).content.decode('utf-8')), sep=',', header='infer', error_bad_lines=False)\n",
    "\n",
    "# download and parse the dataset...\n",
    "data_kg_fake_news2 = get_parsed_data2('https://github.com/synle/machine-learning-sample-dataset/raw/master/liar_dataset/kaggle/kaggle-fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "keb914mJnqRA",
    "outputId": "d6f27690-c2a0-4988-c026-8b729f8b7f07"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_venv/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "data_kg_nonfake_news2 = get_parsed_data2('https://dock2.hyunwookshin.com/public/cmpe257_a1/articles1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "id": "HTfr4_5QoZ6c",
    "outputId": "7de89873-c0e9-4ff4-a1b6-a173ed437815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17283</td>\n",
       "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "      <td>non-bs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17284</td>\n",
       "      <td>Rift Between Officers and Residents as Killing...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Benjamin Mueller and Al Baker</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After the bullet shells get counted, the blood...</td>\n",
       "      <td>non-bs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17285</td>\n",
       "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Margalit Fox</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
       "      <td>non-bs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17286</td>\n",
       "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>William McDonald</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
       "      <td>non-bs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17287</td>\n",
       "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Choe Sang-Hun</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
       "      <td>non-bs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                              title  \\\n",
       "0           0  17283  House Republicans Fret About Winning Their Hea...   \n",
       "1           1  17284  Rift Between Officers and Residents as Killing...   \n",
       "2           2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...   \n",
       "3           3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
       "4           4  17287  Kim Jong-un Says North Korea Is Preparing to T...   \n",
       "\n",
       "      publication                         author        date    year  month  \\\n",
       "0  New York Times                     Carl Hulse  2016-12-31  2016.0   12.0   \n",
       "1  New York Times  Benjamin Mueller and Al Baker  2017-06-19  2017.0    6.0   \n",
       "2  New York Times                   Margalit Fox  2017-01-06  2017.0    1.0   \n",
       "3  New York Times               William McDonald  2017-04-10  2017.0    4.0   \n",
       "4  New York Times                  Choe Sang-Hun  2017-01-02  2017.0    1.0   \n",
       "\n",
       "   url                                               text    type  \n",
       "0  NaN  WASHINGTON  —   Congressional Republicans have...  non-bs  \n",
       "1  NaN  After the bullet shells get counted, the blood...  non-bs  \n",
       "2  NaN  When Walt Disney’s “Bambi” opened in 1942, cri...  non-bs  \n",
       "3  NaN  Death may be the great equalizer, but it isn’t...  non-bs  \n",
       "4  NaN  SEOUL, South Korea  —   North Korea’s leader, ...  non-bs  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_kg_nonfake_news2.rename(columns={\"content\": \"text\"}, inplace=True)\n",
    "data_kg_nonfake_news2['type'] = 'non-bs'\n",
    "print(data_kg_nonfake_news2.shape)\n",
    "data_kg_nonfake_news2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WNJtZRjQogz4"
   },
   "source": [
    "Combine those two datasets, mark data \"bias 443 bs 11492 conspiracy 430 fake 19 hate 246 junksci 102 satire 146 state 121\" to \"bs\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "colab_type": "code",
    "id": "AToqf_k1oc-Y",
    "outputId": "32e90339-3bfc-4a1a-c352-53f8f89c378e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yuxu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "(12999, 20)\n",
      "type\n",
      "bias            443\n",
      "bs            11492\n",
      "conspiracy      430\n",
      "fake             19\n",
      "hate            246\n",
      "junksci         102\n",
      "satire          146\n",
      "state           121\n",
      "Name: type, dtype: int64\n",
      "(50000, 11)\n",
      "type\n",
      "non-bs    50000\n",
      "Name: type, dtype: int64\n",
      "type\n",
      "bs        12999\n",
      "non-bs    50000\n",
      "Name: type, dtype: int64\n",
      "(62999, 2)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from string import punctuation\n",
    "from nltk import PorterStemmer\n",
    "import copy \n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "cachedStopWords = set(stopwords.words('english') + list(punctuation) + [''])\n",
    "print(data_kg_fake_news2.shape)\n",
    "print(data_kg_fake_news2.groupby(['type'])['type'].count())\n",
    "\n",
    "print(data_kg_nonfake_news2.shape)\n",
    "print(data_kg_nonfake_news2.groupby(['type'])['type'].count())\n",
    "\n",
    "data_kg_fake_news_b2=copy.deepcopy(data_kg_fake_news2);\n",
    "data_kg_fake_news_b2.loc[data_kg_fake_news_b2['type']!='non-bs', 'type'] = 'bs'\n",
    "\n",
    "all_data2 = pd.concat([data_kg_fake_news_b2[['text','type']], data_kg_nonfake_news2[['text','type']]])\n",
    "\n",
    "print(all_data2.groupby(['type'])['type'].count())\n",
    "\n",
    "print(all_data2.shape)\n",
    "X2=all_data2['text'].astype('U')\n",
    "y2=all_data2['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert social_reliability_factors.shape[0] == 62999, \"Please review your csv\" # INSERTED BY JAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ce5oPqjOqHox"
   },
   "source": [
    "Now try to use TfidfVectorizer to get a matrix for further classification. Also tried applying SVD for dimension reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize2(text):\n",
    "    min_length = 3\n",
    "    words = map(lambda word: word.lower(), word_tokenize(text))\n",
    "    words = [word for word in words if word not in cachedStopWords]\n",
    "    tokens = list(map(lambda token: PorterStemmer().stem(token), words))\n",
    "    p = re.compile('[a-zA-Z]+')\n",
    "    filtered_tokens = list(filter(lambda token: p.match(token) and len(token) >= min_length, tokens))\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "87NenXuEqIl7"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer, MaxAbsScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3)\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize2)\n",
    "\n",
    "# svd_transformer = Pipeline([('tfidf', vectorizer), \n",
    "#                             ('svd', svd_model)])\n",
    "# svd_transformer=vectorizer\n",
    "    \n",
    "vectorised_train_documents = vectorizer.fit_transform(X_train2)\n",
    "vectorised_test_documents = vectorizer.transform(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YL5cEiNCqO5t"
   },
   "source": [
    "Now do modeling and tuning\n",
    "- Random forest  \n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "colab_type": "code",
    "id": "pXVV28AyqSCA",
    "outputId": "c5a194b2-488c-4126-f3c0-7820836f7059"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_venv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44099, 176904)\n",
      "u.s.         0.020709\n",
      "cnn          0.006176\n",
      "sourc        0.005056\n",
      "said         0.005043\n",
      "so-cal       0.004668\n",
      "accord       0.004322\n",
      "also         0.003953\n",
      "n't          0.003901\n",
      "donald       0.003516\n",
      "year         0.003481\n",
      "novemb       0.003123\n",
      "share        0.003079\n",
      "hillari      0.003014\n",
      "follow       0.002970\n",
      "clinton      0.002873\n",
      "advertis     0.002722\n",
      "week         0.002647\n",
      "breitbart    0.002484\n",
      "elect        0.002445\n",
      "twitter      0.002319\n",
      "dtype: float64\n",
      "bs         3980\n",
      "non-bs    14920\n",
      "Name: type, dtype: int64\n",
      "Accuracy: 0.8840740740740741\n",
      "[[ 2046  1934]\n",
      " [  257 14663]]\n"
     ]
    }
   ],
   "source": [
    "gs=RandomForestClassifier()\n",
    "gs.fit(vectorised_train_documents, y_train2)\n",
    "print(vectorised_train_documents.shape)\n",
    "feature_imp = pd.Series(gs.feature_importances_,index=list(vectorizer.get_feature_names())).sort_values(ascending=False).nlargest(20)\n",
    "print(feature_imp)\n",
    "\n",
    "y_pred2=gs.predict(vectorised_test_documents)\n",
    "print(y_test2.value_counts(sort=False))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred2))\n",
    "print(metrics.confusion_matrix(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "K5INVTKsxDJq",
    "outputId": "8a20f6cb-2707-440d-f460-6442785c4302"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_venv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l1'}\n",
      "Accuracy: 0.9578306878306878\n",
      "F1: 0.898947635349309\n",
      "[[ 3545   435]\n",
      " [  362 14558]]\n"
     ]
    }
   ],
   "source": [
    "# logistic = LogisticRegression()\n",
    "# logistic = LogisticRegression(class_weight='balanced')\n",
    "logistic = LogisticRegression(class_weight={\"bs\":5,\"non-bs\":3})\n",
    "C = [0.1, 1]\n",
    "penalty = ['l1','l2']\n",
    "\n",
    "param_grid = dict(C=C, penalty=penalty)\n",
    "gs = GridSearchCV(logistic, param_grid=param_grid, cv= 5, scoring='accuracy')\n",
    "\n",
    "gs.fit(vectorised_train_documents, y_train2)\n",
    "print(gs.best_params_)\n",
    "\n",
    "y_pred2=gs.predict(vectorised_test_documents)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred2))\n",
    "print(\"F1:\",metrics.f1_score(y_test2, y_pred2, pos_label='bs'))\n",
    "print(metrics.confusion_matrix(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UGZUfsw4bdcD"
   },
   "source": [
    "So by trying different algorithms and model tuning, eventually we found weighted **LogisticRegression** gives pretty good result with accuracy** 95.6%** and parameters LogisticRegression(class_weight={\"bs\":5,\"non-bs\":3}, {'C': 1, 'penalty': 'l1'})  upon raw **TF-IDF** factors.\n",
    "  \n",
    "  Now we can use the model on news like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "m8BfxET1b7Uv",
    "outputId": "b5aba75b-b0bf-4c8d-cde5-30a4c407bd85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['non-bs']\n"
     ]
    }
   ],
   "source": [
    "data = np.array([\"Had President Donald Trump been successful in launching prosecutions against Hillary Clinton and James Comey, it could have spelled the end of his presidency, as a clear-cut abuse of power.\\\n",
    "It never happened, apparently thwarted by then-White House Counsel Don McGahn and other senior officials. But that does not mean this is a crisis dodged for Trump and he is now free from fresh legal and political jeopardy. Quite the reverse.\\\n",
    "RELATED: Trump raised prosecuting Clinton with top White House, Justice officials\\\n",
    "At the very least, the latest developments underline how Trump's senior subordinates may have shielded a President unschooled in constitutional norms from disastrous steps that could have put his presidency in peril.\\\n",
    "And it leaves anyone on the outside wondering what other potential disasters top officials like McGahn, former Attorney General Jeff Sessions and current Deputy Attorney General Rod Rosenstein might have prevented.\\\n",
    "They also raise questions about the capacity of a now-understaffed White House and legal counsel's operation to protect the President from current or future transgressions.\\\n",
    "It will be impossible to confirm, given the habitual silence from the special counsel's office, but the revelations hint at the possibility that Robert Mueller knows much more about what went on in the corridors of the West Wing than has been publicly revealed.\\\n",
    "That will play into rising tensions in Washington amid expectations that the endgame of Mueller's probe is in sight and speculation about possible indictments targeting Trump world and the content of his final report.\\\n",
    "Bombshell reports by CNN and The New York Times about the President's intentions emerged on another surreal day in Washington that saw shocking disclosures about Ivanka Trump's emails and a huge foreign policy pivot over Saudi Arabia.\"])\n",
    "s = pd.Series(data)\n",
    "\n",
    "vectorised_test_documents = vectorizer.transform(s)\n",
    "y_pred=gs.predict(vectorised_test_documents)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PsqeexTHscMG"
   },
   "source": [
    "## Data Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KMON1jgLB7q_"
   },
   "source": [
    "This is where the magic happens. Please ensure that your dataframe follows\n",
    "the dimensions, and integrate your factor columns to **all_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4-yEA3zsbvx"
   },
   "outputs": [],
   "source": [
    "### Aggregate Multiple CSV Data into One Data Frame\n",
    "\n",
    "# #################################################################################################################################\n",
    "# Only include ones that passed the 62999 Test\n",
    "# This is important because the columns have -----------------------------------------------------+-------------------------------+\n",
    "# to align                                                                                        | (Add your name here)          | (Factor)\n",
    "# ############################################                                                    V                               V\n",
    "\n",
    "all_data[ 'Coverage' ]    = coverage_factor[ 'Coverage' ]                                     # <-- HYUNWOOK (JAMES)              News Coverage\n",
    "all_data[ 'Reputation' ]  = social_reliability_factors[ 'calculated_reputation_score' ]       # <-- SY                            Social Reliability\n",
    "all_data[ 'Spam' ]        = social_reliability_factors[ 'calculated_spam_score' ]             # <-- SY\n",
    "all_data[ 'Social' ]      = social_reliability_factors[ 'calculated_social_score' ]           # <-- SY\n",
    "all_data[ 'title_senti_neg' ]  = sentiment_factors[ 'title_senti_neg' ]                       # <-- MOJDEH                        Sentiment\n",
    "all_data[ 'title_senti_neu' ]  = sentiment_factors[ 'title_senti_neu' ]                       # <-- MOJDEH\n",
    "all_data[ 'title_senti_pos'\t]  = sentiment_factors[ 'title_senti_pos'\t]                       # <-- MOJDEH\n",
    "all_data[ 'title_senti_cmp' ]  = sentiment_factors[ 'title_senti_cmpd' ]                      # <-- MOJDEH\n",
    "all_data[ 'text_senti_neg' ]   = sentiment_factors[ 'text_senti_neg' ]                        # <-- MOJDEH\n",
    "all_data[ 'text_senti_neu' ]   = sentiment_factors[ 'text_senti_neu' ]                        # <-- MOJDEH\n",
    "all_data[ 'text_senti_pos' ]   = sentiment_factors[ 'text_senti_pos' ]                        # <-- MOJDEH\n",
    "all_data[ 'text_senti_cmp' ]   = sentiment_factors[ 'text_senti_cmp' ]                        # <-- MOJDEH\n",
    "all_data[['text_w2v_mean','title_w2v_mean','text_d2v_mean','title_d2v_mean']] = w2v_d2v_factors[['text_w2v_mean','title_w2v_mean','text_d2v_mean','title_d2v_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "id": "VuirfyNm_8Fa",
    "outputId": "8c542720-77f9-40c4-b296-aaed2ba06eb2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>Spam</th>\n",
       "      <th>Social</th>\n",
       "      <th>title_senti_neg</th>\n",
       "      <th>title_senti_neu</th>\n",
       "      <th>title_senti_pos</th>\n",
       "      <th>title_senti_cmp</th>\n",
       "      <th>text_senti_neg</th>\n",
       "      <th>text_senti_neu</th>\n",
       "      <th>text_senti_pos</th>\n",
       "      <th>text_senti_cmp</th>\n",
       "      <th>text_w2v_mean</th>\n",
       "      <th>title_w2v_mean</th>\n",
       "      <th>text_d2v_mean</th>\n",
       "      <th>title_d2v_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
       "      <td>Print They should pay all the back all the mon...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-0.052476</td>\n",
       "      <td>0.066654</td>\n",
       "      <td>-0.220385</td>\n",
       "      <td>-0.114133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
       "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.126095</td>\n",
       "      <td>-0.309628</td>\n",
       "      <td>-0.048451</td>\n",
       "      <td>0.017952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
       "      <td>Red State : \\nFox News Sunday reported this mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.095904</td>\n",
       "      <td>-0.209579</td>\n",
       "      <td>-0.118836</td>\n",
       "      <td>-0.079925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
       "      <td>Email Kayla Mueller was a prisoner and torture...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7783</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8316</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.027249</td>\n",
       "      <td>-0.071950</td>\n",
       "      <td>-0.038647</td>\n",
       "      <td>-0.168344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
       "      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9517</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.075030</td>\n",
       "      <td>-0.066515</td>\n",
       "      <td>-0.155317</td>\n",
       "      <td>-0.074950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Muslims BUSTED: They Stole Millions In Gov’t B...   \n",
       "1  Re: Why Did Attorney General Loretta Lynch Ple...   \n",
       "2  BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
       "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...   \n",
       "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...   \n",
       "\n",
       "                                                text  type  Coverage  \\\n",
       "0  Print They should pay all the back all the mon...     0         0   \n",
       "1  Why Did Attorney General Loretta Lynch Plead T...     0         0   \n",
       "2  Red State : \\nFox News Sunday reported this mo...     0         0   \n",
       "3  Email Kayla Mueller was a prisoner and torture...     0         0   \n",
       "4  Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...     0         0   \n",
       "\n",
       "   Reputation  Spam  Social  title_senti_neg  title_senti_neu  \\\n",
       "0           8  0.00   0.011           0.4588             0.00   \n",
       "1           8  0.00   0.011           0.0000             0.00   \n",
       "2           8  0.00   0.011           0.0000             0.00   \n",
       "3           8  0.68   0.000          -0.7783             0.43   \n",
       "4           8  8.65   0.000           0.0000             0.00   \n",
       "\n",
       "   title_senti_pos  title_senti_cmp  text_senti_neg  text_senti_neu  \\\n",
       "0            0.625            0.375         -0.3400           0.209   \n",
       "1            1.000            0.000         -0.2960           0.063   \n",
       "2            1.000            0.000          0.8957           0.021   \n",
       "3            0.570            0.000          0.8316           0.133   \n",
       "4            1.000            0.000          0.9517           0.066   \n",
       "\n",
       "   text_senti_pos  text_senti_cmp  text_w2v_mean  title_w2v_mean  \\\n",
       "0           0.606           0.185      -0.052476        0.066654   \n",
       "1           0.887           0.050      -0.126095       -0.309628   \n",
       "2           0.871           0.108      -0.095904       -0.209579   \n",
       "3           0.517           0.350      -0.027249       -0.071950   \n",
       "4           0.765           0.170      -0.075030       -0.066515   \n",
       "\n",
       "   text_d2v_mean  title_d2v_mean  \n",
       "0      -0.220385       -0.114133  \n",
       "1      -0.048451        0.017952  \n",
       "2      -0.118836       -0.079925  \n",
       "3      -0.038647       -0.168344  \n",
       "4      -0.155317       -0.074950  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X2.reset_index()['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_all = TfidfVectorizer(tokenizer=tokenize2, min_df=1, max_features=50000)\n",
    "vectorised_all = vectorizer_all.fit_transform(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qF2DLXMI5PT"
   },
   "source": [
    "### Using RandomForrest Classifier To Determine Important Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qaaSug57sYl3"
   },
   "outputs": [],
   "source": [
    "### Define polynomial function\n",
    "all_data[ 'Score' ] = \\\n",
    "    all_data[ 'Coverage' ] * 10 + \\\n",
    "    all_data[ 'Reputation' ] * 10 + \\\n",
    "    all_data[ 'Spam' ]  * 10 + \\\n",
    "    all_data[ 'Social' ] * 200 + \\\n",
    "    all_data[ 'title_senti_neg' ] * 20 + \\\n",
    "    all_data[ 'title_senti_neu' ] + \\\n",
    "    all_data[ 'title_senti_pos'\t] * 20 + \\\n",
    "    all_data[ 'title_senti_cmp' ] + \\\n",
    "    all_data[ 'text_senti_neg' ] * 10 + \\\n",
    "    all_data[' text_senti_neu' ] + \\\n",
    "    all_data[ 'text_senti_pos' ] + \\\n",
    "    all_data[ 'text_senti_cmp' ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "colab_type": "code",
    "id": "MwP7ZRUsI4pG",
    "outputId": "c4cd7551-b681-49ee-c05f-c4c2c271d3de"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "########################################\n",
    "# UPDATE YOUR FACTOR HERE\n",
    "\n",
    "########################################\n",
    "X = all_data[['Coverage', 'Reputation', 'Spam', 'Social', 'title_senti_neg', 'title_senti_neu', 'title_senti_pos', 'title_senti_cmp', 'text_senti_neg', 'text_senti_neu', 'text_senti_pos', 'text_senti_cmp','text_w2v_mean','title_w2v_mean','text_d2v_mean','title_d2v_mean' ]]\n",
    "Y = all_data['type']\n",
    "X_ = X.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = pd.concat([X_, pd.DataFrame(vectorised_all.toarray(), columns=vectorizer_all.vocabulary_)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_venv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train , X_test , Y_train , Y_test = train_test_split(X_, Y, test_size=0.3)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z8nWAd8xJ1eL",
    "outputId": "5a34cb20-0b18-4d33-f67c-ddc3ca56c16d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score Is: 0.8978306878306879\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "Y_pred = clf.predict(X_test)\n",
    "print('Accuracy Score Is:', metrics.accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1s1lOcmWJ7BW"
   },
   "source": [
    "# We got around 90% accuracy in determining if the news is fake or not."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Team Virgo Cluster - Alternus Vera Final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
